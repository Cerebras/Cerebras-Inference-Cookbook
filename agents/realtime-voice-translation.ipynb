{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realtime Voice Translation with Cerebras AI + LiveKit\n",
    "\n",
    "Experience ultra-fast realtime voice translation powered by Cerebras AI's inference and LiveKit's voice infrastructure. Translate conversations to any language in real-time with sub-second latency.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You'll need three API keys:\n",
    "\n",
    "1. **Cerebras API Key** - Get yours at [https://cloud.cerebras.ai](https://cloud.cerebras.ai)\n",
    "2. **OpenAI API Key** - For speech-to-text (Whisper) and text-to-speech. Get it at [https://platform.openai.com](https://platform.openai.com)\n",
    "3. **LiveKit Credentials** - For WebRTC audio streaming\n",
    "\n",
    "### Getting LiveKit Credentials\n",
    "\n",
    "Follow the complete setup guide at:\n",
    "**[https://inference-docs.cerebras.ai/integrations/livekit](https://inference-docs.cerebras.ai/integrations/livekit)**\n",
    "\n",
    "Quick steps:\n",
    "1. Sign up at [LiveKit Cloud](https://cloud.livekit.io/)\n",
    "2. Create a new project\n",
    "3. Go to **Settings â†’ Keys** and generate an API key pair\n",
    "4. Copy your:\n",
    "   - **LIVEKIT_URL** (starts with `wss://`)\n",
    "   - **LIVEKIT_API_KEY**\n",
    "   - **LIVEKIT_API_SECRET**\n",
    "\n",
    "## Running the Translation Agent - Start Jupyter Notebook\n",
    "\n",
    "Start a new terminal and run the following commands:\n",
    "\n",
    "```bash\n",
    "# Install Jupyter\n",
    "pip3 install jupyter\n",
    "```\n",
    "\n",
    "Launch Jupyter with the correct Python kernel:\n",
    "\n",
    "```bash\n",
    "# Register the kernel\n",
    "python3 -m ipykernel install --user --name=translation-agent --display-name=\"Python 3.12 (translation-agent)\"\n",
    "\n",
    "# Start Jupyter\n",
    "jupyter notebook translation_agent.ipynb\n",
    "```\n",
    "\n",
    "**Important:** When you open the notebook, make sure to select the **\"Python 3.12 (translation-agent)\"** kernel from the kernel menu (top right).\n",
    "\n",
    "### Why Jupyter in a Browser?\n",
    "\n",
    "Running Jupyter in a browser (not VS Code or other IDEs) ensures proper microphone access via the LiveKit widget. The browser's native WebRTC support provides the best experience for realtime voice interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Run this cell to install the necessary packages (uncomment if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if packages are not installed\n",
    "!pip3 install \"livekit-agents[openai,silero]>=1.3.0\" python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup & Credentials\n",
    "\n",
    "Set your API keys here. You can also use a `.env` file in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load from .env file if present\n",
    "load_dotenv()\n",
    "\n",
    "# Or set credentials directly (uncomment and fill in):\n",
    "# os.environ[\"CEREBRAS_API_KEY\"] = \"csk-...\"\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"  # For STT/TTS\n",
    "# os.environ[\"LIVEKIT_URL\"] = \"wss://your-project.livekit.cloud\"\n",
    "# os.environ[\"LIVEKIT_API_KEY\"] = \"API...\"\n",
    "# os.environ[\"LIVEKIT_API_SECRET\"] = \"...\"\n",
    "\n",
    "# Verify credentials are set\n",
    "required = [\"OPENAI_API_KEY\", \"CEREBRAS_API_KEY\", \"LIVEKIT_URL\", \"LIVEKIT_API_KEY\", \"LIVEKIT_API_SECRET\"]\n",
    "missing = [k for k in required if not os.getenv(k)]\n",
    "if missing:\n",
    "    print(f\"âš ï¸  Missing environment variables: {missing}\")\n",
    "else:\n",
    "    print(\"âœ… All credentials loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from livekit.agents import (\n",
    "    AutoSubscribe,\n",
    "    JobContext,\n",
    "    WorkerOptions,\n",
    "    AgentSession,\n",
    ")\n",
    "from livekit.agents.voice import Agent as VoiceAgent\n",
    "from livekit.plugins import openai, silero\n",
    "\n",
    "# Suppress verbose logging - only show warnings and above\n",
    "logging.getLogger(\"livekit\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"livekit.agents\").setLevel(logging.WARNING)\n",
    "\n",
    "# Target language for translation\n",
    "TARGET_LANGUAGE = \"Spanish\"  # Change this to your desired target language\n",
    "\n",
    "def get_translation_prompt(target_language: str) -> str:\n",
    "    \"\"\"Generate system prompt for translation.\"\"\"\n",
    "    return f\"\"\"You are a real-time translator. Your task is to translate spoken text to {target_language}.\n",
    "\n",
    "Rules:\n",
    "1. Translate the input text accurately to {target_language}\n",
    "2. Preserve the tone and intent of the original message\n",
    "3. Keep translations natural and conversational\n",
    "4. If the input is already in {target_language}, repeat it with minor improvements if needed\n",
    "5. Do NOT add explanations or commentary - just translate\n",
    "6. Respond ONLY with the translated text\"\"\"\n",
    "\n",
    "\n",
    "async def entrypoint(ctx: JobContext):\n",
    "    \"\"\"LiveKit agent entrypoint.\"\"\"\n",
    "    # Connect to the room\n",
    "    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n",
    "    \n",
    "    print(f\"ðŸŽ¤ Connected to room: {ctx.room.name}\")\n",
    "    \n",
    "    # Create Cerebras LLM client (OpenAI-compatible) with proper headers\n",
    "    cerebras_llm = openai.LLM(\n",
    "        model=\"llama-3.1-8b\",\n",
    "        base_url=\"https://api.cerebras.ai/v1\",\n",
    "        api_key=os.environ[\"CEREBRAS_API_KEY\"],\n",
    "        extra_headers={\"X-Cerebras-3rd-Party-Integration\": \"realtime-translation\"}\n",
    "    )\n",
    "    \n",
    "    # Create voice agent with translation instructions\n",
    "    agent = VoiceAgent(\n",
    "        instructions=get_translation_prompt(TARGET_LANGUAGE),\n",
    "    )\n",
    "    \n",
    "    # Create session with STT/LLM/TTS/VAD components\n",
    "    session = AgentSession(\n",
    "        vad=silero.VAD.load(),\n",
    "        stt=openai.STT(model=\"whisper-1\"),\n",
    "        llm=cerebras_llm,\n",
    "        tts=openai.TTS(model=\"tts-1\", voice=\"alloy\"),\n",
    "    )\n",
    "    \n",
    "    # Start session with agent and room\n",
    "    await session.start(agent=agent, room=ctx.room)\n",
    "    \n",
    "    # Greet the user\n",
    "    await session.say(f\"Translation agent ready. I will translate to {TARGET_LANGUAGE}. Please speak.\")\n",
    "\n",
    "\n",
    "print(f\"âœ… Agent defined. Target language: {TARGET_LANGUAGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the Agent\n",
    "\n",
    "Run this cell to start the agent. It will display an **embedded microphone widget**.\n",
    "\n",
    "### How it works:\n",
    "1. An embedded audio widget appears below (microphone access is requested automatically)\n",
    "2. Click \"Allow\" when your browser asks for microphone permission\n",
    "3. Speak into your microphone - the agent will translate and respond\n",
    "4. To stop: interrupt this cell (Kernel â†’ Interrupt) or restart the kernel\n",
    "\n",
    "**Note:** This cell blocks until you stop it. The agent runs continuously while this cell executes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Change Target Language (Optional)\n",
    "\n",
    "To translate to a different language, change `TARGET_LANGUAGE` in cell 3 and re-run cells 3 and 4.\n",
    "\n",
    "Supported languages:\n",
    "- English\n",
    "- Spanish (EspaÃ±ol)\n",
    "- German (Deutsch)\n",
    "- French (FranÃ§ais)\n",
    "- Italian (Italiano)\n",
    "- Portuguese (PortuguÃªs)\n",
    "- Japanese (æ—¥æœ¬èªž)\n",
    "- Chinese (ä¸­æ–‡)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livekit.agents import jupyter\n",
    "\n",
    "# Run the agent inside the notebook\n",
    "# This cell will display an embedded microphone widget and keep running while the agent is active\n",
    "jupyter.run_app(\n",
    "    WorkerOptions(entrypoint_fnc=entrypoint)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (translation-agent)",
   "language": "python",
   "name": "translation-agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

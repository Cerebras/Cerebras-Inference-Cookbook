{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f47eecf-9238-42d5-9276-4f8aec9a3f03",
   "metadata": {
    "id": "9f47eecf-9238-42d5-9276-4f8aec9a3f03"
   },
   "source": [
    "# Interviewer Voice Agent\n",
    "\n",
    "We all know preparing for an interview is hard, especially when there's no one around to test your skills. Lots of websites offer mock interviews, but they also cost alot! So what can you do when you're a student fresh out of college and want to land the job of your dreams?\n",
    "\n",
    "I have good news for you! You can code your own interview practice agent, and make it feel as human-like as possible by using Livekit voice agents with blazing fast LLMs hosted on Cerebras API cloud. By the end of this tutorial, you'll have a nice, free, and fast personal interview agent to crush all your future interviews...AND you can customize it to the specific job you're preparing for.\n",
    "\n",
    "The diagram bellow shows the general workflow we'll build:\n",
    "\n",
    "![Pipeline.png](https://drive.google.com/file/d/1IqNSzkefjPGX4qTTaTO7fbQHZnX4QXe8/view?usp=drive_link)\n",
    "\n",
    "Basically, our agent will have four major components:\n",
    "* LLM with structured output to understand the resume and job link \n",
    "* Speech to Text (STT) to convert user speech to digestible text for the interviewer \n",
    "* Interviewer LLM to conduct the interview based on the user responses and the conversation context so far \n",
    "* Text to Speech (TTS) to convert the interviewer LLM responses to human-like speech\n",
    "\n",
    "LiveKit helps us put all these together! We'll explain everything in a bit so buckle up and let's get started!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e234000-1561-44e3-a0de-0cb79f9fd376",
   "metadata": {},
   "source": [
    "First, we start by making sure all the packages we need are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec85c62-cfd7-4a70-9f9d-006b5762a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install livekit-agents[openai,silero,deepgram,cartesia,turn-detector]~=1.0\n",
    "!pip install cerebras-cloud-sdk beautifulsoup4 PyPDF2 pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a0b7d-82b3-4c2f-8463-36d29f565e6a",
   "metadata": {
    "id": "218a0b7d-82b3-4c2f-8463-36d29f565e6a"
   },
   "source": [
    "Let's import every package we will need. We will explain how each of these packages are used later.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584218c-2757-4e8e-9eb6-8e96be81f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from livekit.agents import (\n",
    "    Agent,\n",
    "    AgentSession,\n",
    "    JobContext,\n",
    "    RunContext,\n",
    "    WorkerOptions,\n",
    "    cli,\n",
    "    function_tool,\n",
    "    ChatContext,\n",
    "    jupyter\n",
    ")\n",
    "\n",
    "# from dotenv import load_dotenv <---- only if you decided to add your environment variables in a separate .env file.\n",
    "# load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "import requests, os, json, re, sys\n",
    "from bs4 import BeautifulSoup\n",
    "import pdfplumber\n",
    "from livekit.plugins import deepgram, openai, silero\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88d046-79eb-4491-ae1a-8a7cd3c86540",
   "metadata": {
    "id": "ba88d046-79eb-4491-ae1a-8a7cd3c86540"
   },
   "source": [
    "To make our API calls to Cerebras and Livekit, we need to add the following API Keys (replace the `XXXXXX`). To get a Cerebras API Key see our [QuickStart guide](https://inference-docs.cerebras.ai/quickstart) and to get LiveKit API key and secret see the [Voice AI quickstart](https://docs.livekit.io/agents/start/voice-ai/#requirements) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9d88a-0a11-487a-b022-b0e278452402",
   "metadata": {
    "id": "dbae1ad4-03c5-4419-82a7-2bf8bab39cd0"
   },
   "outputs": [],
   "source": [
    "os.environ[\"LIVEKIT_API_KEY\"] = \"<your-api-key>\"\n",
    "os.environ[\"LIVEKIT_API_SECRET\"] = \"<your-api-key>\"\n",
    "os.environ[\"LIVEKIT_URL\"] = \"wss://voice-assistant-<id>.livekit.cloud\"\n",
    "os.environ[\"CEREBRAS_API_KEY\"] = \"<your-api-key>\"\n",
    "os.environ[\"DEEPGRAM_API_KEY\"] = \"<your-api-key>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3991e9-dc07-4ec9-8820-a7e13f950447",
   "metadata": {
    "id": "5a3991e9-dc07-4ec9-8820-a7e13f950447"
   },
   "source": [
    "## Parsing the Job description link\n",
    "\n",
    "Let's start by extracting useful details from the job link. This information will be added to the context of our interviewer agent. Follow the instructions below.\n",
    "\n",
    "We will need two major components:\n",
    "1) A tool to read a given link and extract the text from it. We will use `BeautifulSoup` for this.\n",
    "2) An API call to a [Cerebras supported LLM](https://inference-docs.cerebras.ai/models/overview) to process the input text. We want this LLM to support [structured output](https://inference-docs.cerebras.ai/capabilities/structured-outputs).\n",
    "\n",
    "We will implement all these in a function called `process_link`:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c08bf1-9cda-460a-9b7e-01979c68843d",
   "metadata": {
    "id": "98c08bf1-9cda-460a-9b7e-01979c68843d"
   },
   "source": [
    "Our function looks like this (we will break it down and explain what each segment does):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c26ab4-da2b-4d01-904e-ed399d1d9bfe",
   "metadata": {
    "id": "28c26ab4-da2b-4d01-904e-ed399d1d9bfe"
   },
   "outputs": [],
   "source": [
    "def process_link(link):\n",
    "\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        # Preprocess the text\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split('  '))\n",
    "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "\n",
    "    client = Cerebras(\n",
    "    api_key=os.environ.get(\"CEREBRAS_API_KEY\") )\n",
    "\n",
    "    job_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"job title\": {\"type\": \"string\"},\n",
    "            \"job type\": {\"type\":\"string\", \"enum\":[\"full-time\",\"part-time\",\"contract\",\"internship\"]},\n",
    "            \"location\": {\"type\": \"string\"},\n",
    "            \"start date\": {\"type\": \"string\"},\n",
    "            \"qualifications\": {\"type\": \"string\"},\n",
    "            \"responsibilities\": {\"type\": \"string\"},\n",
    "            \"benefits\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"job title\",\"job type\", \"qualifications\", \"responsibilities\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are a link summarizing aganet. All information you need about the job is here: {text}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Following the given response format, summarize the relevant information about this job.\"}\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"job_schema\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": job_schema\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    # Parse the JSON response\n",
    "    job_data = json.loads(completion.choices[0].message.content)\n",
    "\n",
    "    print(json.dumps(job_data, indent=2))\n",
    "\n",
    "    return job_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd2f55-320d-4bef-b2fb-46b46377b0b4",
   "metadata": {
    "id": "aacd2f55-320d-4bef-b2fb-46b46377b0b4"
   },
   "source": [
    "Now let's break this down:\n",
    "\n",
    "```bash\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        # Preprocess the text\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split('  '))\n",
    "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "```\n",
    "\n",
    "We first get the html link and remove leading and trailing whitespace characters (spaces, tabs, newlines, etc.) from each line. Then, we split each line into phrases wherever there are two or more spaces (`' '`). All this is wrapped inside `try:... except:...` to catch any exceptions. The resulting text will be used as context for our LLM.\n",
    "\n",
    "To make the API call to the LLM, we need:\n",
    "\n",
    "```bash\n",
    "    client = Cerebras(api_key=os.environ.get(\"CEREBRAS_API_KEY\") )\n",
    "```\n",
    "\n",
    "The next step will be to define the structure of our output. The job title, location, start date, qualifications, responsibilities, and benefits are strings that could take any value whereas the job type needs to take one of the options `[\"full-time\",\"part-time\",\"contract\",\"internship\"]`.\n",
    "\n",
    "```bash\n",
    "\n",
    "    job_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"job title\": {\"type\": \"string\"},\n",
    "            \"job type\": {\"type\":\"string\", \"enum\":[\"full-time\",\"part-time\",\"contract\",\"internship\"]},\n",
    "            \"location\": {\"type\": \"string\"},\n",
    "            \"start date\": {\"type\": \"string\"},\n",
    "            \"qualifications\": {\"type\": \"string\"},\n",
    "            \"responsibilities\": {\"type\": \"string\"},\n",
    "            \"benefits\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"job title\",\"job type\", \"qualifications\", \"responsibilities\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "```\n",
    "\n",
    "Now we are ready to make the call and use chat completion with an appropriate system prompt. Remember to add the extracted text in the first step to the system prompt.\n",
    "\n",
    "```bash\n",
    "completion = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are a link summarizing aganet. All information you need about the job is here: {text}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Following the given response format, summarize the relevant information about this job.\"}\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"job_schema\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": job_schema\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "```\n",
    "You can replace the model name with any other model supported by Cerebras (See [supported models](https://inference-docs.cerebras.ai/models/overview)). You might need to change the system and user prompts for the call.\n",
    "\n",
    "Finally, we parse the JSON response and return it as the output to `process_link` function.\n",
    "\n",
    "```bash\n",
    "    job_data = json.loads(completion.choices[0].message.content)\n",
    "    \n",
    "    print(json.dumps(job_data, indent=2)) #to print out the result\n",
    "            \n",
    "    return job_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcbf81c-250d-4bc2-baa2-49abd673c8ba",
   "metadata": {
    "id": "bbcbf81c-250d-4bc2-baa2-49abd673c8ba"
   },
   "source": [
    "## Parsing the resume PDF\n",
    "\n",
    "Now, we do something similar to parse the pdf of the resume file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47284299-0369-48f5-ad14-0f067806b071",
   "metadata": {
    "id": "47284299-0369-48f5-ad14-0f067806b071"
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re, json, os\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "\n",
    "\n",
    "def parse_pdf_to_text(file_path, context_file_path=None):\n",
    "    \"\"\"\n",
    "    Parse a PDF file into plain text, removing bulletpoints and special signs, but preserving characters like @ and .\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "        context_file_path (str, optional): Path to the JSON context file. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: The parsed text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            text = ''\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text()\n",
    "\n",
    "            # Remove bulletpoints and special signs, but preserve characters like @ and .\n",
    "            text = re.sub(r'[\\n\\t\\r]', ' ', text)\n",
    "            text = re.sub(r'[^\\w\\s\\.,!?@:\\-]', '', text)\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            text = text.strip()\n",
    "\n",
    "            if context_file_path:\n",
    "                with open(context_file_path, 'r') as f:\n",
    "                    context_data = json.load(f)\n",
    "                    # You can now use the context data as needed\n",
    "                    print(\"Context Data:\")\n",
    "                    print(json.dumps(context_data, indent=4))\n",
    "\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "\n",
    "    try:\n",
    "        text = parse_pdf_to_text(pdf_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "\n",
    "    client = Cerebras(\n",
    "    api_key=os.environ.get(\"CEREBRAS_API_KEY\") )\n",
    "\n",
    "    resume_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"education\": {\"type\": \"string\"},\n",
    "            \"skills\": {\"type\":\"string\"},\n",
    "            \"languages\": {\"type\":\"string\"},\n",
    "            \"job experience\": {\"type\":\"string\"},\n",
    "            \"publications\": {\"type\":\"string\"},\n",
    "            \"location\": {\"type\": \"string\"},\n",
    "            \"phone number\": {\"type\": \"integer\"},\n",
    "            \"linkedin\": {\"type\": \"string\"},\n",
    "            \"github\": {\"type\": \"string\"},\n",
    "            \"google scholar\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"education\",\"skills\",\"job experience\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are a resume summarizing aganet. All information you need about the candidate is here: {text}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Following the given response format, summarize the relevant information about this candidate.\"}\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"resume_schema\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": resume_schema\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    # Parse the JSON response\n",
    "    candidate_data = json.loads(completion.choices[0].message.content)\n",
    "\n",
    "    print(json.dumps(candidate_data, indent=2))\n",
    "\n",
    "    return candidate_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2744663-ab08-4fce-9317-0ca6af5fbe0c",
   "metadata": {
    "id": "b2744663-ab08-4fce-9317-0ca6af5fbe0c"
   },
   "source": [
    "We will define two functions:\n",
    "\n",
    "1) `parse_pdf_to_text` which converts our pdf file to plain text that will be used as the context to our LLM.\n",
    "2) `process_pdf(` which after calling `parse_pdf_to_text`, makes a Cerebras API call to generate a structured output summarizing the resume content. This function is very similar to `process_link`.\n",
    "   \n",
    "Let's take a look at `parse_pdf_to_text`:\n",
    "\n",
    "```bash\n",
    "with pdfplumber.open(file_path) as pdf:\n",
    "    text = ''\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text()\n",
    "```\n",
    "These lines use the [package](https://github.com/jsvine/pdfplumber) `pdfplumber` to extract information from a pdf file. Then, we remove the unnecessary characters using [Regex](https://docs.python.org/3/library/re.html).\n",
    "```bash\n",
    "text = re.sub(r'[\\n\\t\\r]', ' ', text)  # Replace newline, tab, and return characters with space\n",
    "text = re.sub(r'[^\\w\\s\\.,!?@:\\-]', '', text)  # Remove non-alphanumeric characters, non-spaces, and non-preserved special characters\n",
    "text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
    "text = text.strip()  # Remove leading and trailing spaces\n",
    "```\n",
    "\n",
    "As an optional step, and provided we have a context file path, we can save the results there for later use:\n",
    "```bash\n",
    "if context_file_path:\n",
    "    with open(context_file_path, 'r') as f:\n",
    "        context_data = json.load(f)\n",
    "        # You can now use the context data as needed\n",
    "        print(\"Context Data:\")\n",
    "        print(json.dumps(context_data, indent=4))\n",
    "```\n",
    "The function returns the extracted and cleanedup `text`. Again, all this is wrapped inside `try:... except:...` to catch any exceptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd99563-8fac-4ee2-88dc-00ee58a3ba49",
   "metadata": {
    "id": "3dd99563-8fac-4ee2-88dc-00ee58a3ba49"
   },
   "source": [
    "## Interviewer Agent\n",
    "\n",
    "Even though in this section we are designing a voice agent specifically for an interview practice, the general pipeline can be repurposed to any other voice agent you want to build!\n",
    "\n",
    "Let's build our interviewer agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41db79-5c74-46f4-9567-0d2e47e9a8b4",
   "metadata": {
    "id": "7d41db79-5c74-46f4-9567-0d2e47e9a8b4"
   },
   "outputs": [],
   "source": [
    "class Assistant(Agent):\n",
    "    def __init__(self, chat_ctx: ChatContext) -> None:\n",
    "        super().__init__(chat_ctx=chat_ctx, instructions=\"You are a voice assistant that helps the user practice for an interview.\")\n",
    "\n",
    "async def entrypoint(ctx: JobContext, candidate_context, job_context):\n",
    "    try:\n",
    "\n",
    "        await ctx.connect()\n",
    "\n",
    "        session = AgentSession(\n",
    "            vad=silero.VAD.load(),\n",
    "            stt=deepgram.STT(model=\"nova-3\"),\n",
    "            llm=openai.LLM.with_cerebras(\n",
    "                model=\"llama3.3-70b\",\n",
    "                temperature=0.7,\n",
    "            ),\n",
    "            tts=deepgram.TTS(model=\"aura-2-thalia-en\"),\n",
    "        )\n",
    "        today = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "        chat_ctx = ChatContext()\n",
    "        chat_ctx.add_message(role=\"user\", content=f\"I am interviewing for this job: {job_context}.\")\n",
    "        chat_ctx.add_message(role=\"user\", content=f\"This is my resume: {candidate_context}.\")\n",
    "        chat_ctx.add_message(role=\"assistant\", content=f\"Today's date is {today}. Don't repeat this to the user. This is only for your reference.\")\n",
    "\n",
    "        await session.start(\n",
    "                agent=Assistant(chat_ctx=chat_ctx),\n",
    "                room=ctx.room)\n",
    "\n",
    "        # Initial prompt from assistant\n",
    "        assistant_msg = await session.generate_reply(\n",
    "            instructions=\"In one sentence tell the user that you will conduct a mock interview to help them prepare. No filler or explanation. Then pause.\"\n",
    "        )\n",
    "        chat_ctx.add_message(role=\"assistant\", content=assistant_msg)\n",
    "        # Main interaction loop: listen/respond with context\n",
    "        while True:\n",
    "            user_input = await session.listen()  # STT\n",
    "\n",
    "            if user_input:\n",
    "                chat_ctx.add_message(role=\"user\", content=user_input)\n",
    "\n",
    "                # Step 3: Provide short feedback only\n",
    "                feedback_msg = await session.generate_reply(\n",
    "                    instructions=\"Give a short, informal sentence of feedback, without repeating the user's response. Speak naturally, like a coach. Then, pause.\"\n",
    "                )\n",
    "                chat_ctx.add_message(role=\"assistant\", content=feedback_msg)\n",
    "                await session.speak(feedback_msg)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61757553-8076-4953-b987-732dfe48c04a",
   "metadata": {
    "id": "61757553-8076-4953-b987-732dfe48c04a"
   },
   "source": [
    "Let's break this code down! Good news! LiveKit takes care of many of the major components of this segment through `AgentSession`. All we need to do is choose what we want to use for Speech To Text (STT), Text To Speech (TTS), and Voice Activity Detector (VAD).\n",
    "\n",
    "### JobContext\n",
    "When defining our async `entrypoint` function, an important input is the `JobContext` (here we call it `ctx`). All you need to do, is to connect to the \"room\" where the conversation is happening by using:\n",
    "\n",
    "```bash\n",
    "await ctx.connect()\n",
    "```\n",
    "\n",
    "### Assistant\n",
    "\n",
    "Let's define our Agent subclass called `Assistant` which receives the chat context (subclass of `ChatContext`) and an instruction (system prompt).\n",
    "```bash\n",
    "class Assistant(Agent):\n",
    "    def __init__(self, chat_ctx: ChatContext) -> None:\n",
    "        super().__init__(chat_ctx=chat_ctx, instructions=\"You are a voice assistant that helps the user practice for an interview.\")\n",
    "```\n",
    "\n",
    "### AgentSession\n",
    "\n",
    "The agent session is responsible for collecting user input, managing the voice pipeline, invoking the LLM, and sending the output back to the user (see [LiveKit Docs](https://docs.livekit.io/agents/build/)).\n",
    "\n",
    "```bash\n",
    "session = AgentSession(\n",
    "            vad=silero.VAD.load(),\n",
    "            stt=deepgram.STT(model=\"nova-3\"),\n",
    "            llm=openai.LLM.with_cerebras(\n",
    "                model=\"llama3.3-70b\",\n",
    "                temperature=0.7,\n",
    "            ),\n",
    "            tts=deepgram.TTS(model=\"aura-2-thalia-en\"),\n",
    "        )\n",
    "```\n",
    "Here, for both [STT integration](https://docs.livekit.io/agents/integrations/stt/) and [TTS integration](https://docs.livekit.io/agents/integrations/tts/) we use [Deepgram](https://developers.deepgram.com/home). For VAD we use [Silero](https://github.com/snakers4/silero-vad).\n",
    "\n",
    "In order to ingerate Cerebras with this pipeline, we use the LiveKit plug-in:\n",
    "```bash\n",
    "llm=openai.LLM.with_cerebras(\n",
    "            model=\"llama3.3-70b\",\n",
    "            temperature=0.7,\n",
    "            ),\n",
    "```\n",
    "where we can choose the model name, temperature, etc. See [this page](https://docs.livekit.io/agents/integrations/llm/cerebras/).\n",
    "\n",
    "You may have noticed that our agent receives a `ChatContext` as input. This is to make sure that we preserve the prior conversations. Before connecting the agent, we might want to give it some prior context. We do that as follows:\n",
    "\n",
    "```bash\n",
    "today = datetime.now().strftime(\"%B %d, %Y\")\n",
    "chat_ctx = ChatContext()\n",
    "chat_ctx.add_message(role=\"user\", content=f\"I am interviewing for this job: {job_context}.\")\n",
    "chat_ctx.add_message(role=\"user\", content=f\"This is my resume: {candidate_context}.\")\n",
    "chat_ctx.add_message(role=\"assistant\", content=f\"Today's date is {today}. Don't repeat this to the user. This is only for your reference.\")\n",
    "```\n",
    "Where apart from the `job_context` (extracted from job link) and `candidate_context` (extracted from candidate resume),we add the current date as well for the agent's reference.\n",
    "\n",
    "\n",
    "### Starting the session and generating the first agent message\n",
    "Now that we have all our ingredients, we can start our session and generate the first message:\n",
    "\n",
    "```bash\n",
    "await session.start(\n",
    "                agent=Assistant(chat_ctx=chat_ctx),\n",
    "                room=ctx.room)\n",
    "        \n",
    "# Initial prompt from assistant\n",
    "assistant_msg = await session.generate_reply( instructions=\"Greet the user and start the phone screening process by asking a single question and waiting for the user's response.\" )\n",
    "\n",
    "chat_ctx.add_message(role=\"assistant\", content=assistant_msg)\n",
    "```\n",
    "The last line is to make sure we preserve the last assistant message in our chat context.\n",
    "\n",
    "### The loop!\n",
    "After the first greeting message from the agent, we want the agent to do the following in a loop:\n",
    "1) listen for anything the user says and convert it to text (STT)\n",
    "   `user_input = await session.listen()`\n",
    "3) If the user speaks,\n",
    "   \n",
    "   a)  Add their message to the running chat context \\\n",
    "       `chat_ctx.add_message(role=\"user\", content=user_input)` \\\n",
    "   b) Generate an appropriate reply using the integrated LLM \\\n",
    "       `feedback_msg = await session.generate_reply(\n",
    "   instructions=\"Give a brief, specific feedback on the user's response. Then, after a pause ask the next question.\")` \\\n",
    "   c) Add the agent reply to the context \\\n",
    "       `chat_ctx.add_message(role=\"assistant\", content=feedback_msg)` \\\n",
    "   d) Speak the agent reply (TTS) \\\n",
    "       `await session.speak(feedback_msg)`\n",
    "\n",
    "\n",
    "And of course, wrap all this in a `try:... except` to catch the exceptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a663fd2-cf65-4c2a-9e91-914ba3cd1f5c",
   "metadata": {
    "id": "8a663fd2-cf65-4c2a-9e91-914ba3cd1f5c"
   },
   "source": [
    "## Putting it all together\n",
    "\n",
    "Optionally, you can implement a user interface to make your application more user friendly. To keep it simple, let's just use `input()` to receive the pdf path and job link. Let's put everything together in our `main.py` file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4de68-700b-4add-a33a-7c48c628ca76",
   "metadata": {
    "id": "b8a4de68-700b-4add-a33a-7c48c628ca76",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "\n",
    "# get the resume path and job link as inputs, optionally this could be implemented in a GUI\n",
    "pdf = str(input(\"Resume Path: \"))\n",
    "link = str(input(\"Job Link: \"))\n",
    "# process the contents and extract useful information\n",
    "job_context = process_link(link)\n",
    "candidate_context = process_pdf(pdf)\n",
    "\n",
    "# run your application!\n",
    "jupyter.run_app(WorkerOptions(entrypoint_fnc=lambda ctx: entrypoint(ctx, candidate_context, job_context)),\n",
    "               jupyter_url=\"https://jupyter-api-livekit.vercel.app/api/join-token\"\n",
    "               )\n",
    "#entrypoint(None, candidate_context, job_context)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1285b9-10c1-413a-807f-0382b80481b7",
   "metadata": {
    "id": "f365c3c2-edec-49f3-89f8-bab8688393cc"
   },
   "source": [
    "That's it! Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93872c9c-9ee2-4338-9e9f-be9bb4e2ed20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
